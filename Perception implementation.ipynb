{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Help functions and imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#all imported libraries are part of standard library\n",
    "import random\n",
    "import math\n",
    "import tkinter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Part of help functions relies on python pseudo random number generator.\n",
    "\n",
    "- **dot_product** takes two vectors and returns their the dot_product\n",
    "- **random_sample** takes three integers as input and returns the list of random unique integers in the asked interval\n",
    "- **shuffle_list** takes a list and returns the list shuffled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def dot_product(vector_a,vector_b):\n",
    "    if len(vector_a)!=len(vector_b): \n",
    "        print (\"Error: vector of different lengths\")\n",
    "        return False\n",
    "    return sum([vector_a[i]*vector_b[i] for i in range(len(vector_a))])\n",
    " \n",
    "#note that both lower and upper limit are included\n",
    "def random_sample(lower_limit,upper_limit,sample_size):\n",
    "    if sample_size > (upper_limit-lower_limit+1):\n",
    "        print (\"The asked sample size is to large\")\n",
    "    random_set=set([])\n",
    "    random_list=[]\n",
    "    while(len(random_set)<sample_size):\n",
    "        a=random.randint(lower_limit,upper_limit)\n",
    "        if a not in random_set:\n",
    "            random_set.add(a)\n",
    "            random_list.append(a)     \n",
    "    return(random_list)\n",
    "\n",
    "def shuffle_list(a_list):\n",
    "    list_indices=list(range(len(a_list)))\n",
    "    list_of_final_indices=[]\n",
    "    for i in range(len(a_list)):\n",
    "        current_choice=random.choice(list_indices)\n",
    "        list_of_final_indices.append(current_choice)\n",
    "        list_indices.remove(current_choice)\n",
    "    return [a_list[i] for i in list_of_final_indices]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**load_data_with_ones** takes a file with two comma separated numeric columns (coordinates on the real plane) and a second file with one numeric column.\n",
    "\n",
    "The function returns list with four columns\n",
    "- column 1 is made of ones for easier calculation of half step prediciton\n",
    "- column 2 is the first column from the file with the data, $x_1$\n",
    "- column 3 is the second column from the file with the data, $x_2$\n",
    "- column 4 is the column with classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def load_data_with_ones(training_data,training_class):\n",
    "\n",
    "    train_data_file=open(training_data)\n",
    "    train_data_file_lines=train_data_file.readlines()\n",
    "    train_data_file.close()\n",
    "    train_class_file=open(training_class)\n",
    "    train_class_file_lines=train_class_file.readlines()\n",
    "    train_class_file.close()\n",
    "    data_list=[]\n",
    "    for i in range(len(train_data_file_lines)):\n",
    "        temp_list=[1]\n",
    "        temp_line=train_data_file_lines[i].strip(\"\\n\")\n",
    "        for j in train_data_file_lines[i].split(\",\"):\n",
    "            temp_list.append(j)\n",
    "        temp_list=[float(i) for i in temp_list]\n",
    "        temp_line=train_class_file_lines[i].strip(\"\\n\")\n",
    "        temp_list.append(float(temp_line))\n",
    "        data_list.append(temp_list)\n",
    "    return data_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Implementation of the Perceptron algorithm with Stochastic Gradient Descent (SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**unit_step_prediction** takes a single data point $(x_1,x_2)$ and a set of weights and returns predictions of its class\n",
    "\n",
    "**learn_weigths** takes a train dataset, and two parameters, learning rate $\\eta$ $(0<\\eta<1)$ and epoch. It returns learned weigths.\n",
    "\n",
    "**evaluation_metrics** takes a test dataset and learned weigths and returns the rate of success for the classification with the current weigths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def unit_step_prediction(data_row, weigths):\n",
    "    z=dot_product(data_row,weigths)\n",
    "    if z>=0:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def learn_weigths(data, epoch_num, learning_rate):\n",
    "    weigths=[random.random()*random.choice([-1,1]) for i in range(len(data[0])-1)]\n",
    "    for epoch in range(epoch_num):\n",
    "        data_shuffled=shuffle_list(data)\n",
    "        number_of_missclassified=0\n",
    "        for data_row in data_shuffled:\n",
    "            difference = unit_step_prediction(data_row[0:3],weigths)-data_row[3]\n",
    "            if difference!=0:\n",
    "                number_of_missclassified+=1\n",
    "                for i in range(len(weigths)):\n",
    "                    weigths[i]=weigths[i]-difference*data_row[i]*learning_rate\n",
    "        #print(\"Epoch: %d\" % (epoch+1), \"Learning rate: %.2f\" % learning_rate, \"Success rate: %.2f %%\" % ((1-number_of_missclassified/len(data))*100))\n",
    "        if number_of_missclassified==0:\n",
    "            data_shuffled.clear()\n",
    "            return epoch+1,weigths\n",
    "    data_shuffled.clear()\n",
    "    return epoch+1,weigths\n",
    "\n",
    "def evaluation_metrics(test_data,calculated_weigths):\n",
    "    num_all=len(test_data)\n",
    "    num_true=0\n",
    "    for test_row in test_data:\n",
    "        if test_row[3]==unit_step_prediction(test_row[0:3],calculated_weigths):\n",
    "            num_true+=1\n",
    "    return (num_true)/num_all*100\n",
    "\n",
    "def perceptron(train_data,train_class,epoch, learning_rate):\n",
    "    data=load_data_with_ones(train_data,train_class)\n",
    "    final_epoch,learned_weigths=learn_weigths(data,epoch,learning_rate)\n",
    "    print(\"Evaluated success of the classifier is %.2f %%\" % (evaluation_metrics(data,learned_weigths)), \", reached in\",final_epoch, \"epoch(s)\", \"with learning rate of\", learning_rate )\n",
    "    print(\"Learned weigths are:\")\n",
    "    print(\"w0 = \", \"{0:.2f}\".format(learned_weigths[0]))\n",
    "    print(\"w1 = \", \"{0:.2f}\".format(learned_weigths[1]))\n",
    "    print(\"w2 = \", \"{0:.2f}\".format(learned_weigths[2]))\n",
    "    data.clear()\n",
    "    return learned_weigths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# The modification of the Perceptron "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In perceptron for linearly separable data the classifier equation is $y=-w_1/w_2*x-w_0/w_2$, if we assume that the classifier is non_linear function with three parameters, we can imagine that the maybe it could be power function, exponential or logarithmic. Higher order polynomials would require more parameters.\n",
    "The equation of implemented non linear classifier is: $y=-e^{w_1*x}/w_2-w_0/w_2$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**exponential_prediction** takes a single data point  (x1,x2)(x1,x2)  and a set of weights and returns predictions of its class\n",
    "\n",
    "**learn_weigths** takes a train dataset, and two parameters, learning rate  ηη   (0<η<1)(0<η<1)  and epoch. It returns learned weigths.\n",
    "\n",
    "**evaluation_metrics** takes a test dataset and learned weigths and returns the rate of success for the classification with the current weigths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def exponential_prediction(data_row, weigths):\n",
    "    #data_row[1]=math.exp(data_row[1])\n",
    "    #z=dot_product(data_row,weigths)\n",
    "    z=math.exp(data_row[1]*weigths[1])+weigths[0]+weigths[2]*data_row[2]\n",
    "    if z>=0:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def learn_weigths_non_linear(data, epoch_num, learning_rate):\n",
    "    weigths=[random.random()*random.choice([-1,1]) for i in range(len(data[0])-1)]\n",
    "    for epoch1 in range(epoch_num):\n",
    "        data_shuffled=shuffle_list(data)\n",
    "        number_of_missclassified=0\n",
    "        for data_row in data_shuffled:\n",
    "            difference = exponential_prediction(data_row[0:3],weigths)-data_row[3]\n",
    "            if difference!=0:\n",
    "                number_of_missclassified+=1\n",
    "                for i in range(len(weigths)):\n",
    "                    weigths[i]=weigths[i]-difference*data_row[i]*learning_rate\n",
    "        #print(\"Epoch: %d\" % (epoch+1), \"Learning rate: %.2f\" % learning_rate, \"Success rate: %.2f %%\" % ((1-number_of_missclassified/len(data))*100))\n",
    "        if number_of_missclassified==0:\n",
    "            data_shuffled.clear()\n",
    "            return epoch1+1,weigths\n",
    "    data_shuffled.clear()\n",
    "    return epoch1+1,weigths\n",
    "\n",
    "def evaluation_metrics_non_lin(test_data,calculated_weigths):\n",
    "    num_all=len(test_data)\n",
    "    num_true=0\n",
    "    for test_row in test_data:\n",
    "        if test_row[3]==exponential_prediction(test_row[0:3],calculated_weigths):\n",
    "            num_true+=1\n",
    "    return (num_true)/num_all*100\n",
    "\n",
    "\n",
    "def perceptron_non_linear_modification(train_data,train_class,epoch, learning_rate):\n",
    "    data=load_data_with_ones(train_data,train_class)\n",
    "    final_epoch,learned_weigths=learn_weigths_non_linear(data,epoch,learning_rate)\n",
    "    print(\"Evaluated success of the classifier is %.2f %%\" % (evaluation_metrics_non_lin(data,learned_weigths)), \", reached in\",final_epoch, \"epoch(s)\", \"with learning rate of\", learning_rate )\n",
    "    print(\"Learned weigths are:\")\n",
    "    print(\"w0 = \", \"{0:.2f}\".format(learned_weigths[0]))\n",
    "    print(\"w1 = \", \"{0:.2f}\".format(learned_weigths[1]))\n",
    "    print(\"w2 = \", \"{0:.2f}\".format(learned_weigths[2]))\n",
    "    data.clear()\n",
    "    return learned_weigths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# he chart "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "I hardcoded a chart using tkinter. I am used to relying on different tools such as matplotlib, gnuplot, matlab to make plots, it takes the learned weigths of both classifiers and plots their equations on a real plane with samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def make_a_chart(linear_weigths,non_linear_weigts):\n",
    "    \n",
    "    #import data\n",
    "    data_for_plot=load_data_with_ones(\"linsep-traindata.csv\",\"linsep-trainclass.csv\")\n",
    "    data_for_non_lin_plot= load_data_with_ones(\"nonlinsep-traindata.csv\",\"nonlinsep-trainclass.csv\")\n",
    "    #create window\n",
    "    chart=tkinter.Tk()\n",
    "    chart.title(\"Perceptron\")\n",
    "    #create canvas\n",
    "    plots = tkinter.Canvas(chart, bg=\"white\", height=600, width=1100)\n",
    "    #add elements to canvas\n",
    "    plots.create_rectangle(100,100,500,500,fill=\"light grey\", outline=\"black\")\n",
    "    plots.create_rectangle(600,100,1000,500,fill=\"light grey\", outline=\"black\") \n",
    "    \n",
    "    for data_line in data_for_plot:\n",
    "        data_line[1]=int(data_line[1]*25+275)\n",
    "        data_line[2]=int(data_line[2]*(-25)+325) \n",
    "        if data_line[3]==-1:\n",
    "            plots.create_oval(data_line[1],data_line[2],data_line[1]+4,data_line[2]+4,fill=\"red\")\n",
    "        else:\n",
    "            plots.create_oval(data_line[1],data_line[2],data_line[1]+4,data_line[2]+4,fill=\"blue\")  \n",
    "    \n",
    "    for data_line in data_for_non_lin_plot:\n",
    "        data_line[1]=int(data_line[1]*66.67+800)\n",
    "        data_line[2]=int(data_line[2]*(-66.67)+350) \n",
    "        if data_line[3]==-1:\n",
    "            plots.create_oval(data_line[1],data_line[2],data_line[1]+4,data_line[2]+4,fill=\"red\")\n",
    "        else:\n",
    "            plots.create_oval(data_line[1],data_line[2],data_line[1]+4,data_line[2]+4,fill=\"blue\")     \n",
    "    w0= str(\"{0:.2f}\".format(linear_weigths[0]))\n",
    "    w1= str(\"{0:.2f}\".format(linear_weigths[1]))\n",
    "    w2= str(\"{0:.2f}\".format(linear_weigths[2])) \n",
    "    lequation=\"Equation of linear classifier is y=-(\" + w1+\"x+\" + w0 +\")/\"+w2\n",
    "    line_x=[(-7 + i * 0.1) for i in range(160)]\n",
    "    line_y=[(-linear_weigths[1]*x-linear_weigths[0])/linear_weigths[2] for x in line_x]\n",
    "    for i in range(len(line_x)):\n",
    "        if (line_y[i]<9) and (line_y[i]>-7):\n",
    "            line_x[i]=int(line_x[i]*25+275)\n",
    "            line_y[i]=int(line_y[i]*(-25)+325)\n",
    "            plots.create_oval(line_x[i],line_y[i],line_x[i]+1,line_y[i]+1,fill=\"black\")\n",
    "    w1= str(\"{0:.2f}\".format(non_linear_weigths[1]))\n",
    "    w0= str(\"{0:.2f}\".format(non_linear_weigths[0]))\n",
    "    w2= str(\"{0:.2f}\".format(non_linear_weigths[2]))\n",
    "    nlequation=\"Equation of non linear classifier is y=-(exp(\" + w1+\"x)+\" + w0 +\")/\"+w2\n",
    "    exp_x=[(-2.95 + i * 0.05) for i in range(120)]\n",
    "    exp_y=[]\n",
    "    for j in range(len(exp_x)):\n",
    "        exp_y.append(-(math.exp(non_linear_weigths[1]*exp_x[j])+non_linear_weigths[0])/non_linear_weigths[2])\n",
    "          \n",
    "    for i in range(len(exp_x)):\n",
    "        exp_x[i]=int(exp_x[i]*66.67+800)\n",
    "        exp_y[i]=int(exp_y[i]*(-66.67)+350)\n",
    "        plots.create_oval(exp_x[i],exp_y[i],exp_x[i]+1,exp_y[i]+1,fill=\"black\")\n",
    "                \n",
    "    plots.create_text(90,100,text=\"9\")\n",
    "    plots.create_text(90,500,text=\"-7\")\n",
    "    plots.create_text(500,510,text=\"9\")\n",
    "    plots.create_text(100,510,text=\"-7\")\n",
    "    plots.create_text(590,100,text=\"3\")\n",
    "    plots.create_text(590,500,text=\"-3\")\n",
    "    plots.create_text(600,510,text=\"-3\")\n",
    "    plots.create_text(1000,510,text=\"3\")\n",
    "    plots.create_text(135,110,text= \"Class -1\", fill=\"red\")\n",
    "    plots.create_text(635,110,text= \"Class -1\", fill=\"red\")\n",
    "    plots.create_text(135,490,text= \"Class 1\", fill=\"blue\")\n",
    "    plots.create_text(635,490,text= \"Class 1\", fill=\"blue\")\n",
    "    plots.create_text(300,80,text=lequation)\n",
    "    plots.create_text(800,80,text=nlequation)\n",
    "    \n",
    "\n",
    "    plots.pack()\n",
    "    tkinter.Button(chart, text=\"Bye\", command=chart.destroy).pack()                 \n",
    "    chart.mainloop()\n",
    "    data_for_plot.clear()\n",
    "    data_for_non_lin_plot.clear()\n",
    "    line_x.clear()\n",
    "    line_y.clear()\n",
    "    exp_x.clear()\n",
    "    exp_y.clear()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# The execution and the model (run here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#change parameters if you want (learning rates should be in the (0,1) interval)\n",
    "\n",
    "#parameters for the clasic perceptron function\n",
    "max_epoch_lin=100\n",
    "learning_rate_lin=0.1\n",
    "#parameters for the modified perceptron function\n",
    "max_epoch_non_lin=100\n",
    "learning_rate_non_lin=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated success of the classifier is 100.00 % , reached in 1 epoch(s) with learning rate of 0.1\n",
      "Learned weigths are:\n",
      "w0 =  -0.30\n",
      "w1 =  -0.83\n",
      "w2 =  -0.39\n",
      "Evaluated success of the classifier is 100.00 % , reached in 7 epoch(s) with learning rate of 0.1\n",
      "Learned weigths are:\n",
      "w0 =  -1.93\n",
      "w1 =  -0.54\n",
      "w2 =  -1.33\n"
     ]
    }
   ],
   "source": [
    "#execution of the program\n",
    "linear_weigths=perceptron(\"linsep-traindata.csv\",\"linsep-trainclass.csv\",max_epoch_lin,learning_rate_lin)\n",
    "non_linear_weigths=perceptron_non_linear_modification(\"nonlinsep-traindata.csv\",\"nonlinsep-trainclass.csv\",max_epoch_non_lin,learning_rate_non_lin)\n",
    "make_a_chart(linear_weigths,non_linear_weigths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Comments and questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Should the provided sample be split into the train sample and the test sample, or the test sample should be subset of the train sample? \n",
    "- Should the sample be shuffled in each epoch?\n",
    "- Does the learning with the subset of the whole sample destroy the balance of classes for training?\n",
    "- Is it enough to evaluate the function with a simple ratio success/all? \n",
    "- The calculated weigths will be always a bit different as the initial weigths are random, and also because the data is being shuffled. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# References\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. https://sebastianraschka.com/Articles/2015_singlelayer_neurons.html#the-unit-step-function"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
