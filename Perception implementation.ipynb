{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Help functions and imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#all imported libraries are part of python standard standard library\n",
    "import random\n",
    "import math\n",
    "import tkinter\n",
    "import statistics as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Various functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Part of help functions relies on python pseudo random number generator.\n",
    "\n",
    "- **dot_product** takes two vectors and returns their the dot_product\n",
    "- **random_sample** takes three integers as input and returns the list of random unique integers in the asked interval\n",
    "- **shuffle_list** takes a list and returns the list shuffled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def dot_product(vector_a,vector_b):\n",
    "    if len(vector_a)!=len(vector_b): \n",
    "        print (\"Error: vector of different lengths\")\n",
    "        return False\n",
    "    return sum([vector_a[i]*vector_b[i] for i in range(len(vector_a))])\n",
    " \n",
    "#note that both lower and upper limit are included\n",
    "def random_sample(lower_limit,upper_limit,sample_size):\n",
    "    if sample_size > (upper_limit-lower_limit+1):\n",
    "        print (\"The asked sample size is to large\")\n",
    "    random_set=set([])\n",
    "    random_list=[]\n",
    "    while(len(random_set)<sample_size):\n",
    "        a=random.randint(lower_limit,upper_limit)\n",
    "        if a not in random_set:\n",
    "            random_set.add(a)\n",
    "            random_list.append(a)     \n",
    "    return(random_list)\n",
    "\n",
    "def shuffle_list(a_list):\n",
    "    list_indices=list(range(len(a_list)))\n",
    "    list_of_final_indices=[]\n",
    "    for i in range(len(a_list)):\n",
    "        current_choice=random.choice(list_indices)\n",
    "        list_of_final_indices.append(current_choice)\n",
    "        list_indices.remove(current_choice)\n",
    "    return [a_list[i] for i in list_of_final_indices]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**load_data_with_ones** takes a file with two comma separated numeric columns (coordinates on the real plane) and a second file with one numeric column.\n",
    "\n",
    "The function returns list with four columns\n",
    "- column 1 is made of ones for easier calculation of half step prediciton\n",
    "- column 2 is the first column from the file with the data, $x_1$\n",
    "- column 3 is the second column from the file with the data, $x_2$\n",
    "- column 4 is the column with classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Also the csv library can be used.\n",
    "def load_data_with_ones(training_data,training_class):\n",
    "\n",
    "    train_data_file=open(training_data)\n",
    "    train_data_file_lines=train_data_file.readlines()\n",
    "    train_data_file.close()\n",
    "    train_class_file=open(training_class)\n",
    "    train_class_file_lines=train_class_file.readlines()\n",
    "    train_class_file.close()\n",
    "    data_list=[]\n",
    "    for i in range(len(train_data_file_lines)):\n",
    "        temp_list=[1]\n",
    "        temp_line=train_data_file_lines[i].strip(\"\\n\")\n",
    "        for j in train_data_file_lines[i].split(\",\"):\n",
    "            temp_list.append(j)\n",
    "        temp_list=[float(i) for i in temp_list]\n",
    "        temp_line=train_class_file_lines[i].strip(\"\\n\")\n",
    "        temp_list.append(float(temp_line))\n",
    "        data_list.append(temp_list)\n",
    "    return data_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Implementation of the Perceptron algorithm with Stochastic Gradient Descent (SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**unit_step_prediction** takes a single data point $(x_1,x_2)$ and a set of weights and returns predictions of its class\n",
    "\n",
    "**learn_weigths** takes a train dataset, and two parameters, learning rate $\\eta$ $(0<\\eta<1)$ and epoch. It returns learned weigths.\n",
    "\n",
    "**evaluation_metrics** takes a test dataset and learned weigths and returns the rate of success for the classification with the current weigths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def unit_step_prediction(data_row, weigths):\n",
    "    z=dot_product(data_row,weigths)\n",
    "    if z>=0:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def learn_weigths(data, epoch_num, learning_rate):\n",
    "    weigths=[random.random()*random.choice([-1,1]) for i in range(len(data[0])-1)]\n",
    "    for epoch in range(epoch_num):\n",
    "        data_shuffled=shuffle_list(data)\n",
    "        number_of_missclassified=0\n",
    "        for data_row in data_shuffled:\n",
    "            difference = unit_step_prediction(data_row[0:3],weigths)-data_row[3]\n",
    "            if difference!=0:\n",
    "                number_of_missclassified+=1\n",
    "                for i in range(len(weigths)):\n",
    "                    weigths[i]=weigths[i]-difference*data_row[i]*learning_rate\n",
    "        #print(\"Epoch: %d\" % (epoch+1), \"Learning rate: %.2f\" % learning_rate, \"Success rate: %.2f %%\" % ((1-number_of_missclassified/len(data))*100))\n",
    "        if number_of_missclassified==0:\n",
    "            data_shuffled.clear()\n",
    "            return epoch+1,weigths\n",
    "    data_shuffled.clear()\n",
    "    return epoch+1,weigths\n",
    "\n",
    "def evaluation_metrics(test_data,calculated_weigths):\n",
    "    num_all=len(test_data)\n",
    "    num_true=0\n",
    "    for test_row in test_data:\n",
    "        if test_row[3]==unit_step_prediction(test_row[0:3],calculated_weigths):\n",
    "            num_true+=1\n",
    "    return (num_true)/num_all*100\n",
    "\n",
    "def perceptron(train_data,train_class,epoch, learning_rate):\n",
    "    data=load_data_with_ones(train_data,train_class)\n",
    "    final_epoch,learned_weigths=learn_weigths(data,epoch,learning_rate)\n",
    "    evaluation=evaluation_metrics(data,learned_weigths)\n",
    "    print(\"Evaluated success of the classifier is %.2f %%\" % (evaluation), \", reached in\",final_epoch, \"epoch(s)\", \"with learning rate of\", learning_rate )\n",
    "    print(\"Learned weigths are:\")\n",
    "    print(\"w0 = \", \"{0:.2f}\".format(learned_weigths[0]))\n",
    "    print(\"w1 = \", \"{0:.2f}\".format(learned_weigths[1]))\n",
    "    print(\"w2 = \", \"{0:.2f}\".format(learned_weigths[2]))\n",
    "    data.clear()\n",
    "    return final_epoch,learned_weigths,evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# The modification of the Perceptron for non linearly separable data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In perceptron for linearly separable data the classifier equation is $y=-w_1/w_2*x-w_0/w_2$, if we assume that the classifier is non_linear function with three parameters, we can imagine that the maybe it could be power function, exponential or logarithmic. Higher order polynomials would require more parameters.\n",
    "The equation of implemented non linear classifier is: $y=-e^{w_1*x}/w_2-w_0/w_2$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**exponential_prediction** takes a single data point  (x1,x2)(x1,x2)  and a set of weights and returns predictions of its class\n",
    "\n",
    "**learn_weigths** takes a train dataset, and two parameters, learning rate  ηη   (0<η<1)(0<η<1)  and epoch. It returns learned weigths.\n",
    "\n",
    "**evaluation_metrics** takes a test dataset and learned weigths and returns the rate of success for the classification with the current weigths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def exponential_prediction(data_row, weigths):\n",
    "    z=math.exp(data_row[1]*weigths[1])+weigths[0]+weigths[2]*data_row[2]\n",
    "    if z>=0:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def learn_weigths_non_linear(data, epoch_num, learning_rate):\n",
    "    weigths=[random.random()*random.choice([-1,1]) for i in range(len(data[0])-1)]\n",
    "    for epoch1 in range(epoch_num):\n",
    "        data_shuffled=shuffle_list(data)\n",
    "        number_of_missclassified=0\n",
    "        for data_row in data_shuffled:\n",
    "            difference = exponential_prediction(data_row[0:3],weigths)-data_row[3]\n",
    "            if difference!=0:\n",
    "                number_of_missclassified+=1\n",
    "                for i in range(len(weigths)):\n",
    "                    if i==1:\n",
    "                        weigths[i]=weigths[i]- difference/math.fabs(difference)*math.log(math.fabs(difference))*data_row[i]*learning_rate\n",
    "                    else:\n",
    "                        weigths[i]=weigths[i]-difference*data_row[i]*learning_rate\n",
    "        #print(\"Epoch: %d\" % (epoch+1), \"Learning rate: %.2f\" % learning_rate, \"Success rate: %.2f %%\" % ((1-number_of_missclassified/len(data))*100))\n",
    "        if number_of_missclassified==0:\n",
    "            data_shuffled.clear()\n",
    "            return epoch1+1,weigths\n",
    "    data_shuffled.clear()\n",
    "    return epoch1+1,weigths\n",
    "\n",
    "def evaluation_metrics_non_lin(test_data,calculated_weigths):\n",
    "    num_all=len(test_data)\n",
    "    num_true=0\n",
    "    for test_row in test_data:\n",
    "        if test_row[3]==exponential_prediction(test_row[0:3],calculated_weigths):\n",
    "            num_true+=1\n",
    "    return (num_true)/num_all*100\n",
    "\n",
    "\n",
    "def perceptron_non_linear_modification(train_data,train_class,epoch, learning_rate):\n",
    "    data=load_data_with_ones(train_data,train_class)\n",
    "    final_epoch,learned_weigths=learn_weigths_non_linear(data,epoch,learning_rate)\n",
    "    evaluation=evaluation_metrics_non_lin(data,learned_weigths)\n",
    "    print(\"Evaluated success of the classifier is %.2f %%\" % (evaluation), \", reached in\",final_epoch, \"epoch(s)\", \"with learning rate of\", learning_rate )\n",
    "    print(\"Learned weigths are:\")\n",
    "    print(\"w0 = \", \"{0:.2f}\".format(learned_weigths[0]))\n",
    "    print(\"w1 = \", \"{0:.2f}\".format(learned_weigths[1]))\n",
    "    print(\"w2 = \", \"{0:.2f}\".format(learned_weigths[2]))\n",
    "    data.clear()\n",
    "    return final_epoch,learned_weigths,evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# The chart "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "I hardcoded a chart using tkinter. I am used to relying on different tools such as matplotlib, gnuplot, matlab to make plots, it takes the learned weigths of both classifiers and other parameters and plots their equations on a real plane with samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def make_a_chart(linear_weigths,non_linear_weigts, epoch_lin,learning_rate_lin,epoch_non_lin,learning_rate_non_lin,eval_lin,eval_non_lin):\n",
    "    \n",
    "    #import data\n",
    "    data_for_plot=load_data_with_ones(\"linsep-traindata.csv\",\"linsep-trainclass.csv\")\n",
    "    data_for_non_lin_plot= load_data_with_ones(\"nonlinsep-traindata.csv\",\"nonlinsep-trainclass.csv\")\n",
    "    #create window\n",
    "    chart=tkinter.Tk()\n",
    "    chart.title(\"Perceptron\")\n",
    "    #create canvas\n",
    "    plots = tkinter.Canvas(chart, bg=\"white\", height=600, width=1100)\n",
    "    #add elements to canvas\n",
    "    plots.create_rectangle(100,100,500,500,fill=\"light grey\", outline=\"black\")\n",
    "    plots.create_rectangle(600,100,1000,500,fill=\"light grey\", outline=\"black\") \n",
    "    \n",
    "    \n",
    "    \n",
    "    for data_line in data_for_plot:\n",
    "        data_line[1]=int(data_line[1]*25+275)\n",
    "        data_line[2]=int(data_line[2]*(-25)+325) \n",
    "        if data_line[3]==-1:\n",
    "            plots.create_oval(data_line[1],data_line[2],data_line[1]+4,data_line[2]+4,fill=\"red\")\n",
    "        else:\n",
    "            plots.create_oval(data_line[1],data_line[2],data_line[1]+4,data_line[2]+4,fill=\"blue\")  \n",
    "    \n",
    "    for data_line in data_for_non_lin_plot:\n",
    "        data_line[1]=int(data_line[1]*66.67+800)\n",
    "        data_line[2]=int(data_line[2]*(-66.67)+333.33) \n",
    "        if data_line[3]==-1:\n",
    "            plots.create_oval(data_line[1],data_line[2],data_line[1]+4,data_line[2]+4,fill=\"red\")\n",
    "        else:\n",
    "            plots.create_oval(data_line[1],data_line[2],data_line[1]+4,data_line[2]+4,fill=\"blue\")     \n",
    "    \n",
    "    w0= str(\"{0:.2f}\".format(linear_weigths[0]))\n",
    "    w1= str(\"{0:.2f}\".format(linear_weigths[1]))\n",
    "    w2= str(\"{0:.2f}\".format(linear_weigths[2])) \n",
    "    lequation=\"Equation of linear classifier is y=-(\" + w1+\"x+\" + w0 +\")/\"+w2\n",
    "    \n",
    "    line_x=[(-7 + i * 0.1) for i in range(160)]\n",
    "    line_y=[(-linear_weigths[1]*x-linear_weigths[0])/linear_weigths[2] for x in line_x]\n",
    "    for i in range(len(line_x)):\n",
    "        if (line_y[i]<9) and (line_y[i]>-7):\n",
    "            line_x[i]=int(line_x[i]*25+275)\n",
    "            line_y[i]=int(line_y[i]*(-25)+325)\n",
    "            plots.create_oval(line_x[i],line_y[i],line_x[i]+1,line_y[i]+1,fill=\"black\")\n",
    "    \n",
    "    w1= str(\"{0:.2f}\".format(non_linear_weigths[1]))\n",
    "    w0= str(\"{0:.2f}\".format(non_linear_weigths[0]))\n",
    "    w2= str(\"{0:.2f}\".format(non_linear_weigths[2]))\n",
    "    nlequation=\"Equation of non linear classifier is y=-(exp(\" + w1+\"x)+\" + w0 +\")/\"+w2\n",
    "    \n",
    "    exp_x=[(-2.95 + i * 0.05) for i in range(120)]\n",
    "    exp_y=[]\n",
    "    for j in range(len(exp_x)):\n",
    "        exp_y.append(-(math.exp(non_linear_weigths[1]*exp_x[j])+non_linear_weigths[0])/non_linear_weigths[2])\n",
    "          \n",
    "    for i in range(len(exp_x)):\n",
    "        if (exp_y[i]<3.5) and (exp_y[i]>-2.5):\n",
    "            exp_x[i]=int(exp_x[i]*66.67+800)\n",
    "            exp_y[i]=int(exp_y[i]*(-66.67)+333.33)\n",
    "            plots.create_oval(exp_x[i],exp_y[i],exp_x[i]+1,exp_y[i]+1,fill=\"black\")\n",
    "    \n",
    "    plots.create_text(90,100,text=\"9\")\n",
    "    plots.create_text(90,500,text=\"-7\")\n",
    "    plots.create_text(500,510,text=\"9\")\n",
    "    plots.create_text(100,510,text=\"-7\")\n",
    "    plots.create_text(590,100,text=\"3\")\n",
    "    plots.create_text(580,500,text=\"-2.5\")\n",
    "    plots.create_text(600,510,text=\"-3\")\n",
    "    plots.create_text(1000,510,text=\"3\")\n",
    "    plots.create_text(135,110,text= \"Class -1\", fill=\"red\")\n",
    "    plots.create_text(635,110,text= \"Class -1\", fill=\"red\")\n",
    "    plots.create_text(135,490,text= \"Class 1\", fill=\"blue\")\n",
    "    plots.create_text(635,490,text= \"Class 1\", fill=\"blue\")\n",
    "    plots.create_text(300,80,text=lequation)\n",
    "    plots.create_text(800,80,text=nlequation)\n",
    "    plots.create_text(300,60,text=(\"Number of epochs needed: \"+ str(epoch_lin)))\n",
    "    plots.create_text(800,60,text=(\"Number of epochs needed: \"+ str(epoch_non_lin)))\n",
    "    plots.create_text(300,40,text=(\"Learning rate: \"+ str(learning_rate_lin)))\n",
    "    plots.create_text(800,40,text=(\"Learning rate: \"+ str(learning_rate_non_lin)))\n",
    "    plots.create_text(300,540,text=(\"Evaluated quality of the classifier: \"+ str(eval_lin) + \" %\"))\n",
    "    plots.create_text(800,540,text=(\"Evaluated quality of the classifier: \"+ str(eval_non_lin)+ \" %\"))\n",
    "\n",
    "    plots.pack()\n",
    "    tkinter.Button(chart, text=\"Bye\", command=chart.destroy).pack()                 \n",
    "    chart.mainloop()\n",
    "    data_for_plot.clear()\n",
    "    data_for_non_lin_plot.clear()\n",
    "    line_x.clear()\n",
    "    line_y.clear()\n",
    "    exp_x.clear()\n",
    "    exp_y.clear()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# The execution and the model (run and change parameters here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#change parameters if you want (learning rates should be in the (0,1) interval) and epoch should be positive integer\n",
    "\n",
    "#parameters for the perceptron function\n",
    "max_epoch_lin=100\n",
    "learning_rate_lin=0.1\n",
    "#parameters for the modified perceptron function\n",
    "max_epoch_non_lin=100\n",
    "learning_rate_non_lin=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated success of the classifier is 100.00 % , reached in 2 epoch(s) with learning rate of 0.1\n",
      "Learned weigths are:\n",
      "w0 =  -0.72\n",
      "w1 =  -0.81\n",
      "w2 =  -0.81\n",
      "Evaluated success of the classifier is 100.00 % , reached in 15 epoch(s) with learning rate of 0.1\n",
      "Learned weigths are:\n",
      "w0 =  -1.90\n",
      "w1 =  -0.47\n",
      "w2 =  -1.25\n"
     ]
    }
   ],
   "source": [
    "#execution of the program\n",
    "#all cells above should be executed first\n",
    "final_epoch_lin,linear_weigths,evaluation_lin=perceptron(\"linsep-traindata.csv\",\"linsep-trainclass.csv\",max_epoch_lin,learning_rate_lin)\n",
    "final_epoch_non_lin,non_linear_weigths,evaluation_non_lin=perceptron_non_linear_modification(\"nonlinsep-traindata.csv\",\"nonlinsep-trainclass.csv\",max_epoch_non_lin,learning_rate_non_lin)\n",
    "make_a_chart(linear_weigths,non_linear_weigths,final_epoch_lin,learning_rate_lin,final_epoch_non_lin,learning_rate_non_lin,evaluation_lin,evaluation_non_lin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Some properties of the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Properties of the linearly separable data\n",
      "Training sample is composed of equal number of each class, mean value of the classes of the whole sample is: 0.0\n",
      "Mean and standard deviation of the sample\n",
      "Class -1, coordinate x: 3.49382432 2.244669569682184\n",
      "Class -1, coordinate y: 3.7950998 2.1103647361284277\n",
      "Class  1, coordinate x: -3.390084 1.0274804558169046\n",
      "Class  1, coordinate y: -3.547274 0.9364283732831871\n"
     ]
    }
   ],
   "source": [
    "data=load_data_with_ones(\"linsep-traindata.csv\",\"linsep-trainclass.csv\")\n",
    "list_of_classes=[data[i][3] for i in range(len(data))]\n",
    "list_of_x_neg=[data[i][1] for i in range(len(data)) if data[i][3]==-1 ]\n",
    "list_of_y_neg=[data[i][2] for i in range(len(data)) if data[i][3]==-1]\n",
    "list_of_x_pos=[data[i][1] for i in range(len(data)) if data[i][3]==1]\n",
    "list_of_y_pos=[data[i][2] for i in range(len(data)) if data[i][3]==1]\n",
    "print(\"Properties of the linearly separable data\")\n",
    "print(\"Training sample is composed of equal number of each class, mean value of the classes of the whole sample is:\",stats.mean(list_of_classes))\n",
    "print(\"Mean and standard deviation of the sample\")\n",
    "print(\"Class -1, coordinate x:\",stats.mean(list_of_x_neg),stats.stdev(list_of_x_neg))\n",
    "print(\"Class -1, coordinate y:\",stats.mean(list_of_y_neg),stats.stdev(list_of_y_neg))\n",
    "print(\"Class  1, coordinate x:\",stats.mean(list_of_x_pos),stats.stdev(list_of_x_pos))\n",
    "print(\"Class  1, coordinate y:\",stats.mean(list_of_y_pos),stats.stdev(list_of_y_pos))\n",
    "list_of_classes.clear()\n",
    "list_of_x_neg.clear()\n",
    "list_of_x_pos.clear()\n",
    "list_of_y_neg.clear()\n",
    "list_of_y_pos.clear()\n",
    "list_of_classes.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Properties of the linearly non separable data\n",
      "Training sample is composed of equal number of each class, mean value of the classes of the whole sample is: 0.0\n",
      "Mean and standard deviation of the sample\n",
      "Class -1, coordinate x: 0.0467366 1.068616852383854\n",
      "Class -1, coordinate y: -0.24302462 0.7617860774735961\n",
      "Class  1, coordinate x: 0.165596864 1.0377973396158682\n",
      "Class  1, coordinate y: -1.0166386 0.30543693838606534\n"
     ]
    }
   ],
   "source": [
    "data=load_data_with_ones(\"nonlinsep-traindata.csv\",\"nonlinsep-trainclass.csv\")\n",
    "list_of_classes=[data[i][3] for i in range(len(data))]\n",
    "list_of_x_neg=[data[i][1] for i in range(len(data)) if data[i][3]==-1 ]\n",
    "list_of_y_neg=[data[i][2] for i in range(len(data)) if data[i][3]==-1]\n",
    "list_of_x_pos=[data[i][1] for i in range(len(data)) if data[i][3]==1]\n",
    "list_of_y_pos=[data[i][2] for i in range(len(data)) if data[i][3]==1]\n",
    "print(\"Properties of the linearly non separable data\")\n",
    "print(\"Training sample is composed of equal number of each class, mean value of the classes of the whole sample is:\",stats.mean(list_of_classes))\n",
    "print(\"Mean and standard deviation of the sample\")\n",
    "print(\"Class -1, coordinate x:\",stats.mean(list_of_x_neg),stats.stdev(list_of_x_neg))\n",
    "print(\"Class -1, coordinate y:\",stats.mean(list_of_y_neg),stats.stdev(list_of_y_neg))\n",
    "print(\"Class  1, coordinate x:\",stats.mean(list_of_x_pos),stats.stdev(list_of_x_pos))\n",
    "print(\"Class  1, coordinate y:\",stats.mean(list_of_y_pos),stats.stdev(list_of_y_pos))\n",
    "list_of_classes.clear()\n",
    "list_of_x_neg.clear()\n",
    "list_of_x_pos.clear()\n",
    "list_of_y_neg.clear()\n",
    "list_of_y_pos.clear()\n",
    "list_of_classes.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Comments and questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Should the provided sample be split into the train sample and the test sample, or the test sample should be subset of the train sample? In my opinion \n",
    "- Should the sample be shuffled in each epoch? Yes. There is the option to choose a part sample for each epoch, and from my point of view as the sample is not very large, and it doesn't make a big impact on the computing time to use the whole sample, shuffling is enough. Also choosing a smaller random sample from the balanced sample (sum of classes==0), increses chances that the sample is unbalanced in regard of classes\n",
    "- Is it enough to evaluate the function with a simple ratio success/all (classification accuracy)? In my opinion yes, as the sample is balanced. \n",
    "- The whole sample is used for the evaluation of the classifier\n",
    "- The calculated weigths will be always a bit different as the initial weigths are random, and also because the data is being shuffled. \n",
    "- All libraries I used are part of standard python librabry, I understood that only libraries I can't use are pip libraries\n",
    "- The representation of the data and classifier is not completely accurate as the coordinate system is made of a descrete number of points, and the preented values are rounded.\n",
    "- The modelling ends as soon as it reaches 0 missclassifications, as the whoe sample is used in each epoch there no chance that there will be a missclassification in the next epoch. Had I used the random subsample in each epoch I would prefere to leave it to run until it reaches the given epoch. Especially if lower percentage of sample is used in each epoch, or if the standard deviation of the sample is high.\n",
    "- The non linear modification of the perceptron will converge only for small learning rates (<0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# References\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. https://sebastianraschka.com/Articles/2015_singlelayer_neurons.html#the-unit-step-function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
